{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "\n",
    "# 모델\n",
    "from xgboost import XGBClassifier \n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 파라미터 최적화\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 평가지표\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('cust_train.csv', encoding = 'UTF-8')\n",
    "label = target.LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd w2v bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('pd_w2v_train.csv', encoding = 'UTF-8')\n",
    "test = pd.read_csv('pd_w2v_test.csv', encoding = 'UTF-8')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size = 0.3, random_state = 516, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.696   \u001b[0m | \u001b[0m 0.9123  \u001b[0m | \u001b[0m 0.9297  \u001b[0m | \u001b[0m 3.781   \u001b[0m | \u001b[0m 65.34   \u001b[0m | \u001b[0m 8.135   \u001b[0m | \u001b[0m 294.8   \u001b[0m | \u001b[0m 113.0   \u001b[0m | \u001b[0m 0.789   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-5.896   \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 1.103   \u001b[0m | \u001b[0m 5.745   \u001b[0m | \u001b[0m 80.65   \u001b[0m | \u001b[0m 2.584   \u001b[0m | \u001b[0m 212.1   \u001b[0m | \u001b[0m 62.69   \u001b[0m | \u001b[0m 0.8719  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.458   \u001b[0m | \u001b[0m 0.8565  \u001b[0m | \u001b[0m 0.9781  \u001b[0m | \u001b[0m 6.776   \u001b[0m | \u001b[0m 20.55   \u001b[0m | \u001b[0m 5.861   \u001b[0m | \u001b[0m 240.8   \u001b[0m | \u001b[0m 67.81   \u001b[0m | \u001b[0m 0.8451  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.955   \u001b[0m | \u001b[0m 0.8397  \u001b[0m | \u001b[0m 0.5528  \u001b[0m | \u001b[0m 9.905   \u001b[0m | \u001b[0m 29.23   \u001b[0m | \u001b[0m 9.431   \u001b[0m | \u001b[0m 198.7   \u001b[0m | \u001b[0m 136.0   \u001b[0m | \u001b[0m 0.7549  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-1.583   \u001b[0m | \u001b[95m 0.879   \u001b[0m | \u001b[95m 0.9297  \u001b[0m | \u001b[95m 4.4     \u001b[0m | \u001b[95m 82.68   \u001b[0m | \u001b[95m 4.066   \u001b[0m | \u001b[95m 174.1   \u001b[0m | \u001b[95m 148.3   \u001b[0m | \u001b[95m 0.8592  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-1.31    \u001b[0m | \u001b[95m 0.9255  \u001b[0m | \u001b[95m 0.1295  \u001b[0m | \u001b[95m 5.885   \u001b[0m | \u001b[95m 57.35   \u001b[0m | \u001b[95m 1.101   \u001b[0m | \u001b[95m 91.62   \u001b[0m | \u001b[95m 161.4   \u001b[0m | \u001b[95m 0.8305  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.636   \u001b[0m | \u001b[0m 0.7666  \u001b[0m | \u001b[0m 0.3256  \u001b[0m | \u001b[0m 7.747   \u001b[0m | \u001b[0m 43.62   \u001b[0m | \u001b[0m 7.249   \u001b[0m | \u001b[0m 312.4   \u001b[0m | \u001b[0m 84.47   \u001b[0m | \u001b[0m 0.8177  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.502   \u001b[0m | \u001b[0m 0.9158  \u001b[0m | \u001b[0m 0.531   \u001b[0m | \u001b[0m 8.654   \u001b[0m | \u001b[0m 95.63   \u001b[0m | \u001b[0m 4.724   \u001b[0m | \u001b[0m 57.43   \u001b[0m | \u001b[0m 80.58   \u001b[0m | \u001b[0m 0.9248  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-1.301   \u001b[0m | \u001b[95m 0.8433  \u001b[0m | \u001b[95m 0.08267 \u001b[0m | \u001b[95m 4.465   \u001b[0m | \u001b[95m 50.82   \u001b[0m | \u001b[95m 8.397   \u001b[0m | \u001b[95m 295.8   \u001b[0m | \u001b[95m 10.87   \u001b[0m | \u001b[95m 0.9335  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.377   \u001b[0m | \u001b[0m 0.9359  \u001b[0m | \u001b[0m 0.4739  \u001b[0m | \u001b[0m 5.193   \u001b[0m | \u001b[0m 98.42   \u001b[0m | \u001b[0m 4.626   \u001b[0m | \u001b[0m 91.0    \u001b[0m | \u001b[0m 188.4   \u001b[0m | \u001b[0m 0.8047  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-1.617   \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.5669  \u001b[0m | \u001b[0m 4.913   \u001b[0m | \u001b[0m 59.45   \u001b[0m | \u001b[0m 8.648   \u001b[0m | \u001b[0m 345.6   \u001b[0m | \u001b[0m 156.7   \u001b[0m | \u001b[0m 0.9073  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-1.471   \u001b[0m | \u001b[0m 0.8046  \u001b[0m | \u001b[0m 0.7901  \u001b[0m | \u001b[0m 3.668   \u001b[0m | \u001b[0m 31.67   \u001b[0m | \u001b[0m 1.65    \u001b[0m | \u001b[0m 90.11   \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 0.8522  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.459   \u001b[0m | \u001b[0m 0.8573  \u001b[0m | \u001b[0m 1.061   \u001b[0m | \u001b[0m 5.641   \u001b[0m | \u001b[0m 54.89   \u001b[0m | \u001b[0m 7.525   \u001b[0m | \u001b[0m 293.3   \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 0.7571  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-17.55   \u001b[0m | \u001b[0m 0.8111  \u001b[0m | \u001b[0m 1.18    \u001b[0m | \u001b[0m 7.16    \u001b[0m | \u001b[0m 91.06   \u001b[0m | \u001b[0m 3.266   \u001b[0m | \u001b[0m 195.9   \u001b[0m | \u001b[0m 54.35   \u001b[0m | \u001b[0m 0.7574  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-1.385   \u001b[0m | \u001b[0m 0.9476  \u001b[0m | \u001b[0m 0.3746  \u001b[0m | \u001b[0m 4.078   \u001b[0m | \u001b[0m 37.49   \u001b[0m | \u001b[0m 3.18    \u001b[0m | \u001b[0m 319.3   \u001b[0m | \u001b[0m 138.2   \u001b[0m | \u001b[0m 0.7593  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.077   \u001b[0m | \u001b[0m 0.7706  \u001b[0m | \u001b[0m 0.7413  \u001b[0m | \u001b[0m 7.648   \u001b[0m | \u001b[0m 94.82   \u001b[0m | \u001b[0m 7.447   \u001b[0m | \u001b[0m 186.5   \u001b[0m | \u001b[0m 99.83   \u001b[0m | \u001b[0m 0.8319  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.083   \u001b[0m | \u001b[0m 0.9155  \u001b[0m | \u001b[0m 0.5236  \u001b[0m | \u001b[0m 9.356   \u001b[0m | \u001b[0m 54.99   \u001b[0m | \u001b[0m 7.612   \u001b[0m | \u001b[0m 314.2   \u001b[0m | \u001b[0m 187.7   \u001b[0m | \u001b[0m 0.8324  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.363   \u001b[0m | \u001b[0m 0.7567  \u001b[0m | \u001b[0m 1.114   \u001b[0m | \u001b[0m 7.417   \u001b[0m | \u001b[0m 58.93   \u001b[0m | \u001b[0m 6.338   \u001b[0m | \u001b[0m 123.1   \u001b[0m | \u001b[0m 167.3   \u001b[0m | \u001b[0m 0.7656  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-21.95   \u001b[0m | \u001b[0m 0.8884  \u001b[0m | \u001b[0m 1.195   \u001b[0m | \u001b[0m 7.436   \u001b[0m | \u001b[0m 51.14   \u001b[0m | \u001b[0m 8.626   \u001b[0m | \u001b[0m 272.1   \u001b[0m | \u001b[0m 188.5   \u001b[0m | \u001b[0m 0.7885  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.226   \u001b[0m | \u001b[0m 0.8507  \u001b[0m | \u001b[0m 0.6897  \u001b[0m | \u001b[0m 9.426   \u001b[0m | \u001b[0m 77.3    \u001b[0m | \u001b[0m 4.915   \u001b[0m | \u001b[0m 282.9   \u001b[0m | \u001b[0m 90.24   \u001b[0m | \u001b[0m 0.7657  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-1.422   \u001b[0m | \u001b[0m 0.9121  \u001b[0m | \u001b[0m 0.9221  \u001b[0m | \u001b[0m 8.228   \u001b[0m | \u001b[0m 45.1    \u001b[0m | \u001b[0m 8.331   \u001b[0m | \u001b[0m 38.76   \u001b[0m | \u001b[0m 14.15   \u001b[0m | \u001b[0m 0.8084  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-1.949   \u001b[0m | \u001b[0m 0.8549  \u001b[0m | \u001b[0m 0.9763  \u001b[0m | \u001b[0m 6.74    \u001b[0m | \u001b[0m 79.57   \u001b[0m | \u001b[0m 9.738   \u001b[0m | \u001b[0m 219.8   \u001b[0m | \u001b[0m 25.25   \u001b[0m | \u001b[0m 0.7882  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-1.648   \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 0.6105  \u001b[0m | \u001b[0m 7.126   \u001b[0m | \u001b[0m 41.13   \u001b[0m | \u001b[0m 7.502   \u001b[0m | \u001b[0m 110.7   \u001b[0m | \u001b[0m 83.4    \u001b[0m | \u001b[0m 0.7747  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-1.396   \u001b[0m | \u001b[0m 0.907   \u001b[0m | \u001b[0m 0.8735  \u001b[0m | \u001b[0m 3.917   \u001b[0m | \u001b[0m 69.5    \u001b[0m | \u001b[0m 3.889   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 181.0   \u001b[0m | \u001b[0m 0.8782  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-1.492   \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.5096  \u001b[0m | \u001b[0m 5.497   \u001b[0m | \u001b[0m 44.65   \u001b[0m | \u001b[0m 2.537   \u001b[0m | \u001b[0m 205.7   \u001b[0m | \u001b[0m 140.3   \u001b[0m | \u001b[0m 0.8603  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-1.372   \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 0.2686  \u001b[0m | \u001b[0m 5.825   \u001b[0m | \u001b[0m 64.37   \u001b[0m | \u001b[0m 3.511   \u001b[0m | \u001b[0m 276.1   \u001b[0m | \u001b[0m 24.16   \u001b[0m | \u001b[0m 0.9098  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-1.302   \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.03109 \u001b[0m | \u001b[0m 9.421   \u001b[0m | \u001b[0m 96.09   \u001b[0m | \u001b[0m 3.115   \u001b[0m | \u001b[0m 232.0   \u001b[0m | \u001b[0m 124.8   \u001b[0m | \u001b[0m 0.8799  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-1.633   \u001b[0m | \u001b[0m 0.807   \u001b[0m | \u001b[0m 0.487   \u001b[0m | \u001b[0m 7.606   \u001b[0m | \u001b[0m 71.73   \u001b[0m | \u001b[0m 2.647   \u001b[0m | \u001b[0m 130.5   \u001b[0m | \u001b[0m 87.81   \u001b[0m | \u001b[0m 0.821   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-1.45    \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.397   \u001b[0m | \u001b[0m 4.594   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 2.19    \u001b[0m | \u001b[0m 246.6   \u001b[0m | \u001b[0m 177.8   \u001b[0m | \u001b[0m 0.8807  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-1.49    \u001b[0m | \u001b[0m 0.7812  \u001b[0m | \u001b[0m 0.1893  \u001b[0m | \u001b[0m 8.423   \u001b[0m | \u001b[0m 21.99   \u001b[0m | \u001b[0m 2.14    \u001b[0m | \u001b[0m 248.5   \u001b[0m | \u001b[0m 124.8   \u001b[0m | \u001b[0m 0.7769  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-22.29   \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 1.175   \u001b[0m | \u001b[0m 9.14    \u001b[0m | \u001b[0m 26.92   \u001b[0m | \u001b[0m 1.351   \u001b[0m | \u001b[0m 303.4   \u001b[0m | \u001b[0m 71.69   \u001b[0m | \u001b[0m 0.8115  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-1.361   \u001b[0m | \u001b[0m 0.7825  \u001b[0m | \u001b[0m 0.2821  \u001b[0m | \u001b[0m 8.599   \u001b[0m | \u001b[0m 48.24   \u001b[0m | \u001b[0m 2.642   \u001b[0m | \u001b[0m 35.97   \u001b[0m | \u001b[0m 123.3   \u001b[0m | \u001b[0m 0.8172  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-1.719   \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 3.687   \u001b[0m | \u001b[0m 81.13   \u001b[0m | \u001b[0m 9.077   \u001b[0m | \u001b[0m 266.3   \u001b[0m | \u001b[0m 52.51   \u001b[0m | \u001b[0m 0.9393  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-1.485   \u001b[0m | \u001b[0m 0.8344  \u001b[0m | \u001b[0m 0.9653  \u001b[0m | \u001b[0m 3.675   \u001b[0m | \u001b[0m 68.98   \u001b[0m | \u001b[0m 4.254   \u001b[0m | \u001b[0m 84.93   \u001b[0m | \u001b[0m 166.8   \u001b[0m | \u001b[0m 0.9169  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-1.817   \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.3685  \u001b[0m | \u001b[0m 9.25    \u001b[0m | \u001b[0m 49.57   \u001b[0m | \u001b[0m 4.277   \u001b[0m | \u001b[0m 332.9   \u001b[0m | \u001b[0m 102.7   \u001b[0m | \u001b[0m 0.8335  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-1.532   \u001b[0m | \u001b[0m 0.8571  \u001b[0m | \u001b[0m 0.7743  \u001b[0m | \u001b[0m 4.19    \u001b[0m | \u001b[0m 40.14   \u001b[0m | \u001b[0m 3.248   \u001b[0m | \u001b[0m 204.6   \u001b[0m | \u001b[0m 16.55   \u001b[0m | \u001b[0m 0.9198  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-2.936   \u001b[0m | \u001b[0m 0.8802  \u001b[0m | \u001b[0m 1.108   \u001b[0m | \u001b[0m 8.115   \u001b[0m | \u001b[0m 47.73   \u001b[0m | \u001b[0m 8.112   \u001b[0m | \u001b[0m 340.1   \u001b[0m | \u001b[0m 64.07   \u001b[0m | \u001b[0m 0.8214  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-10.97   \u001b[0m | \u001b[0m 0.8425  \u001b[0m | \u001b[0m 1.273   \u001b[0m | \u001b[0m 6.914   \u001b[0m | \u001b[0m 54.42   \u001b[0m | \u001b[0m 6.824   \u001b[0m | \u001b[0m 109.0   \u001b[0m | \u001b[0m 13.54   \u001b[0m | \u001b[0m 0.8696  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-1.68    \u001b[0m | \u001b[0m 0.8449  \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 5.439   \u001b[0m | \u001b[0m 30.15   \u001b[0m | \u001b[0m 3.314   \u001b[0m | \u001b[0m 117.6   \u001b[0m | \u001b[0m 108.5   \u001b[0m | \u001b[0m 0.8154  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-1.446   \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.8031  \u001b[0m | \u001b[0m 6.152   \u001b[0m | \u001b[0m 29.68   \u001b[0m | \u001b[0m 9.635   \u001b[0m | \u001b[0m 25.62   \u001b[0m | \u001b[0m 74.41   \u001b[0m | \u001b[0m 0.9032  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 41      \u001b[0m | \u001b[95m-1.298   \u001b[0m | \u001b[95m 0.75    \u001b[0m | \u001b[95m 0.03    \u001b[0m | \u001b[95m 6.156   \u001b[0m | \u001b[95m 59.37   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 313.4   \u001b[0m | \u001b[95m 94.79   \u001b[0m | \u001b[95m 0.8206  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-1.354   \u001b[0m | \u001b[0m 0.8655  \u001b[0m | \u001b[0m 0.3229  \u001b[0m | \u001b[0m 6.947   \u001b[0m | \u001b[0m 49.47   \u001b[0m | \u001b[0m 2.985   \u001b[0m | \u001b[0m 35.99   \u001b[0m | \u001b[0m 125.6   \u001b[0m | \u001b[0m 0.7527  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-1.443   \u001b[0m | \u001b[0m 0.8166  \u001b[0m | \u001b[0m 0.2888  \u001b[0m | \u001b[0m 5.91    \u001b[0m | \u001b[0m 24.86   \u001b[0m | \u001b[0m 2.176   \u001b[0m | \u001b[0m 230.8   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 0.8495  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-1.494   \u001b[0m | \u001b[0m 0.8348  \u001b[0m | \u001b[0m 0.6267  \u001b[0m | \u001b[0m 5.001   \u001b[0m | \u001b[0m 57.77   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 106.5   \u001b[0m | \u001b[0m 105.6   \u001b[0m | \u001b[0m 0.8654  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-1.471   \u001b[0m | \u001b[0m 0.8177  \u001b[0m | \u001b[0m 0.5701  \u001b[0m | \u001b[0m 4.173   \u001b[0m | \u001b[0m 64.35   \u001b[0m | \u001b[0m 9.235   \u001b[0m | \u001b[0m 323.9   \u001b[0m | \u001b[0m 131.7   \u001b[0m | \u001b[0m 0.8766  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-1.707   \u001b[0m | \u001b[0m 0.834   \u001b[0m | \u001b[0m 0.48    \u001b[0m | \u001b[0m 7.153   \u001b[0m | \u001b[0m 81.13   \u001b[0m | \u001b[0m 4.285   \u001b[0m | \u001b[0m 203.5   \u001b[0m | \u001b[0m 129.9   \u001b[0m | \u001b[0m 0.8603  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-1.578   \u001b[0m | \u001b[0m 0.8086  \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 5.239   \u001b[0m | \u001b[0m 44.15   \u001b[0m | \u001b[0m 4.885   \u001b[0m | \u001b[0m 94.93   \u001b[0m | \u001b[0m 130.9   \u001b[0m | \u001b[0m 0.8325  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-1.516   \u001b[0m | \u001b[0m 0.7766  \u001b[0m | \u001b[0m 0.547   \u001b[0m | \u001b[0m 7.292   \u001b[0m | \u001b[0m 55.24   \u001b[0m | \u001b[0m 2.845   \u001b[0m | \u001b[0m 64.27   \u001b[0m | \u001b[0m 146.7   \u001b[0m | \u001b[0m 0.9047  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-1.421   \u001b[0m | \u001b[0m 0.8639  \u001b[0m | \u001b[0m 0.6291  \u001b[0m | \u001b[0m 4.955   \u001b[0m | \u001b[0m 53.61   \u001b[0m | \u001b[0m 2.608   \u001b[0m | \u001b[0m 66.69   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 0.8275  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-1.323   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 5.119   \u001b[0m | \u001b[0m 73.79   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 86.15   \u001b[0m | \u001b[0m 133.3   \u001b[0m | \u001b[0m 0.8181  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-1.449   \u001b[0m | \u001b[0m 0.8668  \u001b[0m | \u001b[0m 0.3595  \u001b[0m | \u001b[0m 8.926   \u001b[0m | \u001b[0m 78.3    \u001b[0m | \u001b[0m 5.858   \u001b[0m | \u001b[0m 80.91   \u001b[0m | \u001b[0m 99.29   \u001b[0m | \u001b[0m 0.8662  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-1.318   \u001b[0m | \u001b[0m 0.7549  \u001b[0m | \u001b[0m 0.1358  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 80.31   \u001b[0m | \u001b[0m 4.172   \u001b[0m | \u001b[0m 54.69   \u001b[0m | \u001b[0m 121.6   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-1.417   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.4835  \u001b[0m | \u001b[0m 6.806   \u001b[0m | \u001b[0m 66.54   \u001b[0m | \u001b[0m 8.183   \u001b[0m | \u001b[0m 45.22   \u001b[0m | \u001b[0m 93.4    \u001b[0m | \u001b[0m 0.7929  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-1.457   \u001b[0m | \u001b[0m 0.8293  \u001b[0m | \u001b[0m 0.7902  \u001b[0m | \u001b[0m 4.872   \u001b[0m | \u001b[0m 86.39   \u001b[0m | \u001b[0m 2.546   \u001b[0m | \u001b[0m 55.58   \u001b[0m | \u001b[0m 153.6   \u001b[0m | \u001b[0m 0.9048  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-1.686   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.6536  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 52.88   \u001b[0m | \u001b[0m 2.648   \u001b[0m | \u001b[0m 73.03   \u001b[0m | \u001b[0m 79.85   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-1.352   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 30.73   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 51.6    \u001b[0m | \u001b[0m 94.9    \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-1.315   \u001b[0m | \u001b[0m 0.8156  \u001b[0m | \u001b[0m 0.04935 \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 57.61   \u001b[0m | \u001b[0m 3.305   \u001b[0m | \u001b[0m 232.7   \u001b[0m | \u001b[0m 122.5   \u001b[0m | \u001b[0m 0.8389  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-1.481   \u001b[0m | \u001b[0m 0.8445  \u001b[0m | \u001b[0m 0.6639  \u001b[0m | \u001b[0m 4.158   \u001b[0m | \u001b[0m 55.24   \u001b[0m | \u001b[0m 7.733   \u001b[0m | \u001b[0m 241.7   \u001b[0m | \u001b[0m 20.82   \u001b[0m | \u001b[0m 0.9315  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-1.319   \u001b[0m | \u001b[0m 0.82    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 216.6   \u001b[0m | \u001b[0m 180.2   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-1.328   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.369   \u001b[0m | \u001b[0m 5.352   \u001b[0m | \u001b[0m 54.54   \u001b[0m | \u001b[0m 8.864   \u001b[0m | \u001b[0m 42.81   \u001b[0m | \u001b[0m 57.61   \u001b[0m | \u001b[0m 0.7579  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-1.349   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 23.07   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 61.2    \u001b[0m | \u001b[0m 128.5   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-1.307   \u001b[0m | \u001b[0m 0.9099  \u001b[0m | \u001b[0m 0.07974 \u001b[0m | \u001b[0m 8.911   \u001b[0m | \u001b[0m 22.34   \u001b[0m | \u001b[0m 8.365   \u001b[0m | \u001b[0m 54.71   \u001b[0m | \u001b[0m 58.91   \u001b[0m | \u001b[0m 0.7742  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-1.314   \u001b[0m | \u001b[0m 0.7602  \u001b[0m | \u001b[0m 0.2012  \u001b[0m | \u001b[0m 5.856   \u001b[0m | \u001b[0m 23.66   \u001b[0m | \u001b[0m 5.475   \u001b[0m | \u001b[0m 29.76   \u001b[0m | \u001b[0m 40.57   \u001b[0m | \u001b[0m 0.7582  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-1.513   \u001b[0m | \u001b[0m 0.8836  \u001b[0m | \u001b[0m 0.564   \u001b[0m | \u001b[0m 5.947   \u001b[0m | \u001b[0m 89.41   \u001b[0m | \u001b[0m 3.112   \u001b[0m | \u001b[0m 253.0   \u001b[0m | \u001b[0m 18.57   \u001b[0m | \u001b[0m 0.7985  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-1.356   \u001b[0m | \u001b[0m 0.8896  \u001b[0m | \u001b[0m 0.9251  \u001b[0m | \u001b[0m 4.47    \u001b[0m | \u001b[0m 53.85   \u001b[0m | \u001b[0m 9.851   \u001b[0m | \u001b[0m 12.74   \u001b[0m | \u001b[0m 42.3    \u001b[0m | \u001b[0m 0.8532  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-3.166   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 1.3     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 99.56   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 57.55   \u001b[0m | \u001b[0m 186.7   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-1.332   \u001b[0m | \u001b[0m 0.8176  \u001b[0m | \u001b[0m 0.2972  \u001b[0m | \u001b[0m 9.988   \u001b[0m | \u001b[0m 73.53   \u001b[0m | \u001b[0m 1.828   \u001b[0m | \u001b[0m 20.49   \u001b[0m | \u001b[0m 69.73   \u001b[0m | \u001b[0m 0.9198  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-1.727   \u001b[0m | \u001b[0m 0.8818  \u001b[0m | \u001b[0m 1.209   \u001b[0m | \u001b[0m 7.095   \u001b[0m | \u001b[0m 76.84   \u001b[0m | \u001b[0m 6.772   \u001b[0m | \u001b[0m 31.66   \u001b[0m | \u001b[0m 31.94   \u001b[0m | \u001b[0m 0.7751  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-1.745   \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 1.201   \u001b[0m | \u001b[0m 7.036   \u001b[0m | \u001b[0m 90.62   \u001b[0m | \u001b[0m 5.724   \u001b[0m | \u001b[0m 24.49   \u001b[0m | \u001b[0m 103.9   \u001b[0m | \u001b[0m 0.8846  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-1.537   \u001b[0m | \u001b[0m 0.76    \u001b[0m | \u001b[0m 0.9294  \u001b[0m | \u001b[0m 7.836   \u001b[0m | \u001b[0m 51.33   \u001b[0m | \u001b[0m 6.467   \u001b[0m | \u001b[0m 12.61   \u001b[0m | \u001b[0m 93.62   \u001b[0m | \u001b[0m 0.7865  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-1.343   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 75.41   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 23.95   \u001b[0m | \u001b[0m 149.3   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-1.333   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 42.1    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 33.24   \u001b[0m | \u001b[0m 162.4   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-1.347   \u001b[0m | \u001b[0m 0.8266  \u001b[0m | \u001b[0m 0.3021  \u001b[0m | \u001b[0m 6.108   \u001b[0m | \u001b[0m 33.67   \u001b[0m | \u001b[0m 2.626   \u001b[0m | \u001b[0m 64.66   \u001b[0m | \u001b[0m 177.7   \u001b[0m | \u001b[0m 0.8732  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-1.475   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.9455  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 77.45   \u001b[0m | \u001b[0m 5.921   \u001b[0m | \u001b[0m 239.3   \u001b[0m | \u001b[0m 95.52   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-26.64   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 1.3     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 34.95   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 218.2   \u001b[0m | \u001b[0m 103.8   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-1.707   \u001b[0m | \u001b[0m 0.8391  \u001b[0m | \u001b[0m 0.7542  \u001b[0m | \u001b[0m 4.815   \u001b[0m | \u001b[0m 73.55   \u001b[0m | \u001b[0m 7.713   \u001b[0m | \u001b[0m 248.2   \u001b[0m | \u001b[0m 132.6   \u001b[0m | \u001b[0m 0.8801  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-1.302   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 40.37   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 194.5   \u001b[0m | \u001b[0m 165.3   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-1.306   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.03    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 65.16   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 224.1   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-1.496   \u001b[0m | \u001b[0m 0.8232  \u001b[0m | \u001b[0m 0.7782  \u001b[0m | \u001b[0m 3.813   \u001b[0m | \u001b[0m 46.75   \u001b[0m | \u001b[0m 3.873   \u001b[0m | \u001b[0m 166.2   \u001b[0m | \u001b[0m 149.8   \u001b[0m | \u001b[0m 0.8221  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-1.518   \u001b[0m | \u001b[0m 0.8702  \u001b[0m | \u001b[0m 0.5044  \u001b[0m | \u001b[0m 6.217   \u001b[0m | \u001b[0m 65.36   \u001b[0m | \u001b[0m 4.961   \u001b[0m | \u001b[0m 140.2   \u001b[0m | \u001b[0m 125.5   \u001b[0m | \u001b[0m 0.8201  \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.75,\n",
       " 'learning_rate': 0.03,\n",
       " 'max_depth': 6,\n",
       " 'min_child_samples': 59,\n",
       " 'min_child_weight': 10.0,\n",
       " 'n_estimators': 313,\n",
       " 'num_leaves': 95,\n",
       " 'subsample': 0.8206383495380686}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3059556  -1.30588738 -1.30921729 -1.30877038]\n",
      "최대성능: -1.3058873815455645\n",
      "평균성능: -1.3074576653509726\n"
     ]
    }
   ],
   "source": [
    "pbounds = {'n_estimators' : (10, 350),\n",
    "           'learning_rate' : (0.03, 1.3),\n",
    "           'max_depth' : (3, 10),\n",
    "           'num_leaves' : (10, 200),\n",
    "           'min_child_samples' : (20, 100),\n",
    "           'min_child_weight' : (1, 10),\n",
    "           'subsample' : (0.75, 0.95),\n",
    "           'colsample_bytree' : (0.75, 0.95)}\n",
    "\n",
    "\n",
    "def lgbm_opt(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, colsample_bytree):\n",
    "    \n",
    "    params = {'n_estimators' : int(round(n_estimators)),\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "              'num_leaves' : int(round(num_leaves)),\n",
    "              'min_child_samples' : int(round(min_child_samples)),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'n_jobs' : -1}\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "    \n",
    "    score = cross_val_score(lgbm, X_train, y_train, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_opt, pbounds = pbounds, random_state = 516)\n",
    "\n",
    "BO_lgbm.maximize(init_points=40, n_iter=40)\n",
    "\n",
    "max_params = BO_lgbm.max['params']\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "display(max_params)\n",
    "\n",
    "# Step9. 최대화 하이퍼파라미터로 재학습\n",
    "lgbm_tun = LGBMClassifier(**max_params)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "scores = cross_val_score(lgbm_tun, X_val, y_val, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_w2v_pred = pd.DataFrame(lgbm_tun.predict_proba(test))\n",
    "clnt_te = pd.DataFrame({'CLNT_ID':[i for i in range(263104,375864)]})\n",
    "pd_w2v_pred = pd.concat([clnt_te, pd_w2v_pred],axis=1)\n",
    "pd_w2v_pred.columns = ['CLNT_ID','F20','F30','F40','M20','M30','M40']\n",
    "pd_w2v_pred.to_csv('pd_w2v_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kwd w2v bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('kwd_w2v_train.csv', encoding = 'UTF-8')\n",
    "test = pd.read_csv('kwd_w2v_test.csv', encoding = 'UTF-8')\n",
    "train = train.iloc[:,1:]\n",
    "test = test.iloc[:,1:]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size = 0.3, random_state = 516, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.364   \u001b[0m | \u001b[0m 0.9123  \u001b[0m | \u001b[0m 0.7113  \u001b[0m | \u001b[0m 2.892   \u001b[0m | \u001b[0m 65.34   \u001b[0m | \u001b[0m 12.1    \u001b[0m | \u001b[0m 426.9   \u001b[0m | \u001b[0m 113.0   \u001b[0m | \u001b[0m 0.789   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.734   \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 0.8463  \u001b[0m | \u001b[0m 5.137   \u001b[0m | \u001b[0m 80.65   \u001b[0m | \u001b[0m 3.463   \u001b[0m | \u001b[0m 317.5   \u001b[0m | \u001b[0m 62.69   \u001b[0m | \u001b[0m 0.8719  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.87    \u001b[0m | \u001b[0m 0.8565  \u001b[0m | \u001b[0m 0.7491  \u001b[0m | \u001b[0m 6.316   \u001b[0m | \u001b[0m 20.55   \u001b[0m | \u001b[0m 8.562   \u001b[0m | \u001b[0m 355.5   \u001b[0m | \u001b[0m 67.81   \u001b[0m | \u001b[0m 0.8451  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.739   \u001b[0m | \u001b[0m 0.8397  \u001b[0m | \u001b[0m 0.4175  \u001b[0m | \u001b[0m 9.892   \u001b[0m | \u001b[0m 29.23   \u001b[0m | \u001b[0m 14.12   \u001b[0m | \u001b[0m 299.8   \u001b[0m | \u001b[0m 136.0   \u001b[0m | \u001b[0m 0.7549  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.428   \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 3.6     \u001b[0m | \u001b[0m 82.68   \u001b[0m | \u001b[0m 5.769   \u001b[0m | \u001b[0m 267.1   \u001b[0m | \u001b[0m 148.3   \u001b[0m | \u001b[0m 0.8592  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-1.231   \u001b[0m | \u001b[95m 0.9255  \u001b[0m | \u001b[95m 0.08759 \u001b[0m | \u001b[95m 5.297   \u001b[0m | \u001b[95m 57.35   \u001b[0m | \u001b[95m 1.156   \u001b[0m | \u001b[95m 158.0   \u001b[0m | \u001b[95m 161.4   \u001b[0m | \u001b[95m 0.8305  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.5     \u001b[0m | \u001b[0m 0.7666  \u001b[0m | \u001b[0m 0.2404  \u001b[0m | \u001b[0m 7.425   \u001b[0m | \u001b[0m 43.62   \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 450.3   \u001b[0m | \u001b[0m 84.47   \u001b[0m | \u001b[0m 0.8177  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.429   \u001b[0m | \u001b[0m 0.9158  \u001b[0m | \u001b[0m 0.4006  \u001b[0m | \u001b[0m 8.462   \u001b[0m | \u001b[0m 95.63   \u001b[0m | \u001b[0m 6.793   \u001b[0m | \u001b[0m 112.8   \u001b[0m | \u001b[0m 80.58   \u001b[0m | \u001b[0m 0.9248  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-1.226   \u001b[0m | \u001b[95m 0.8433  \u001b[0m | \u001b[95m 0.05106 \u001b[0m | \u001b[95m 3.674   \u001b[0m | \u001b[95m 50.82   \u001b[0m | \u001b[95m 12.51   \u001b[0m | \u001b[95m 428.3   \u001b[0m | \u001b[95m 10.87   \u001b[0m | \u001b[95m 0.9335  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.305   \u001b[0m | \u001b[0m 0.9359  \u001b[0m | \u001b[0m 0.356   \u001b[0m | \u001b[0m 4.506   \u001b[0m | \u001b[0m 98.42   \u001b[0m | \u001b[0m 6.64    \u001b[0m | \u001b[0m 157.2   \u001b[0m | \u001b[0m 188.4   \u001b[0m | \u001b[0m 0.8047  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-1.369   \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.4286  \u001b[0m | \u001b[0m 4.186   \u001b[0m | \u001b[0m 59.45   \u001b[0m | \u001b[0m 12.9    \u001b[0m | \u001b[0m 494.2   \u001b[0m | \u001b[0m 156.7   \u001b[0m | \u001b[0m 0.9073  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-1.279   \u001b[0m | \u001b[0m 0.8046  \u001b[0m | \u001b[0m 0.6025  \u001b[0m | \u001b[0m 2.763   \u001b[0m | \u001b[0m 31.67   \u001b[0m | \u001b[0m 2.01    \u001b[0m | \u001b[0m 156.0   \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 0.8522  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-1.767   \u001b[0m | \u001b[0m 0.8573  \u001b[0m | \u001b[0m 0.8136  \u001b[0m | \u001b[0m 5.019   \u001b[0m | \u001b[0m 54.89   \u001b[0m | \u001b[0m 11.15   \u001b[0m | \u001b[0m 425.0   \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 0.7571  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-2.045   \u001b[0m | \u001b[0m 0.8111  \u001b[0m | \u001b[0m 0.9066  \u001b[0m | \u001b[0m 6.754   \u001b[0m | \u001b[0m 91.06   \u001b[0m | \u001b[0m 4.525   \u001b[0m | \u001b[0m 296.1   \u001b[0m | \u001b[0m 54.35   \u001b[0m | \u001b[0m 0.7574  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-1.258   \u001b[0m | \u001b[0m 0.9476  \u001b[0m | \u001b[0m 0.2786  \u001b[0m | \u001b[0m 3.232   \u001b[0m | \u001b[0m 37.49   \u001b[0m | \u001b[0m 4.391   \u001b[0m | \u001b[0m 459.4   \u001b[0m | \u001b[0m 138.2   \u001b[0m | \u001b[0m 0.7593  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.752   \u001b[0m | \u001b[0m 0.7706  \u001b[0m | \u001b[0m 0.5645  \u001b[0m | \u001b[0m 7.312   \u001b[0m | \u001b[0m 94.82   \u001b[0m | \u001b[0m 11.03   \u001b[0m | \u001b[0m 283.6   \u001b[0m | \u001b[0m 99.83   \u001b[0m | \u001b[0m 0.8319  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-1.824   \u001b[0m | \u001b[0m 0.9155  \u001b[0m | \u001b[0m 0.3947  \u001b[0m | \u001b[0m 9.264   \u001b[0m | \u001b[0m 54.99   \u001b[0m | \u001b[0m 11.29   \u001b[0m | \u001b[0m 452.7   \u001b[0m | \u001b[0m 187.7   \u001b[0m | \u001b[0m 0.8324  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-1.978   \u001b[0m | \u001b[0m 0.7567  \u001b[0m | \u001b[0m 0.8552  \u001b[0m | \u001b[0m 7.048   \u001b[0m | \u001b[0m 58.93   \u001b[0m | \u001b[0m 9.304   \u001b[0m | \u001b[0m 199.7   \u001b[0m | \u001b[0m 167.3   \u001b[0m | \u001b[0m 0.7656  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.159   \u001b[0m | \u001b[0m 0.8884  \u001b[0m | \u001b[0m 0.9181  \u001b[0m | \u001b[0m 7.069   \u001b[0m | \u001b[0m 51.14   \u001b[0m | \u001b[0m 12.86   \u001b[0m | \u001b[0m 396.9   \u001b[0m | \u001b[0m 188.5   \u001b[0m | \u001b[0m 0.7885  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-1.877   \u001b[0m | \u001b[0m 0.8507  \u001b[0m | \u001b[0m 0.5242  \u001b[0m | \u001b[0m 9.344   \u001b[0m | \u001b[0m 77.3    \u001b[0m | \u001b[0m 7.09    \u001b[0m | \u001b[0m 411.2   \u001b[0m | \u001b[0m 90.24   \u001b[0m | \u001b[0m 0.7657  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-1.335   \u001b[0m | \u001b[0m 0.9121  \u001b[0m | \u001b[0m 0.7054  \u001b[0m | \u001b[0m 7.975   \u001b[0m | \u001b[0m 45.1    \u001b[0m | \u001b[0m 12.4    \u001b[0m | \u001b[0m 88.07   \u001b[0m | \u001b[0m 14.15   \u001b[0m | \u001b[0m 0.8084  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-1.637   \u001b[0m | \u001b[0m 0.8549  \u001b[0m | \u001b[0m 0.7477  \u001b[0m | \u001b[0m 6.274   \u001b[0m | \u001b[0m 79.57   \u001b[0m | \u001b[0m 14.59   \u001b[0m | \u001b[0m 327.7   \u001b[0m | \u001b[0m 25.25   \u001b[0m | \u001b[0m 0.7882  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-1.535   \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 0.4625  \u001b[0m | \u001b[0m 6.715   \u001b[0m | \u001b[0m 41.13   \u001b[0m | \u001b[0m 11.11   \u001b[0m | \u001b[0m 183.2   \u001b[0m | \u001b[0m 83.4    \u001b[0m | \u001b[0m 0.7747  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-1.27    \u001b[0m | \u001b[0m 0.907   \u001b[0m | \u001b[0m 0.6675  \u001b[0m | \u001b[0m 3.048   \u001b[0m | \u001b[0m 69.5    \u001b[0m | \u001b[0m 5.494   \u001b[0m | \u001b[0m 94.47   \u001b[0m | \u001b[0m 181.0   \u001b[0m | \u001b[0m 0.8782  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-1.395   \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.3838  \u001b[0m | \u001b[0m 4.854   \u001b[0m | \u001b[0m 44.65   \u001b[0m | \u001b[0m 3.39    \u001b[0m | \u001b[0m 309.1   \u001b[0m | \u001b[0m 140.3   \u001b[0m | \u001b[0m 0.8603  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-1.293   \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 0.196   \u001b[0m | \u001b[0m 5.228   \u001b[0m | \u001b[0m 64.37   \u001b[0m | \u001b[0m 4.905   \u001b[0m | \u001b[0m 402.2   \u001b[0m | \u001b[0m 24.16   \u001b[0m | \u001b[0m 0.9098  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-1.235   \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.01085 \u001b[0m | \u001b[0m 9.338   \u001b[0m | \u001b[0m 96.09   \u001b[0m | \u001b[0m 4.29    \u001b[0m | \u001b[0m 343.8   \u001b[0m | \u001b[0m 124.8   \u001b[0m | \u001b[0m 0.8799  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-1.514   \u001b[0m | \u001b[0m 0.807   \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 7.264   \u001b[0m | \u001b[0m 71.73   \u001b[0m | \u001b[0m 3.562   \u001b[0m | \u001b[0m 209.4   \u001b[0m | \u001b[0m 87.81   \u001b[0m | \u001b[0m 0.821   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-1.293   \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.2961  \u001b[0m | \u001b[0m 3.822   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 2.852   \u001b[0m | \u001b[0m 363.2   \u001b[0m | \u001b[0m 177.8   \u001b[0m | \u001b[0m 0.8807  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-1.435   \u001b[0m | \u001b[0m 0.7812  \u001b[0m | \u001b[0m 0.1342  \u001b[0m | \u001b[0m 8.198   \u001b[0m | \u001b[0m 21.99   \u001b[0m | \u001b[0m 2.774   \u001b[0m | \u001b[0m 365.7   \u001b[0m | \u001b[0m 124.8   \u001b[0m | \u001b[0m 0.7769  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-7.095   \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.9028  \u001b[0m | \u001b[0m 9.017   \u001b[0m | \u001b[0m 26.92   \u001b[0m | \u001b[0m 1.547   \u001b[0m | \u001b[0m 438.4   \u001b[0m | \u001b[0m 71.69   \u001b[0m | \u001b[0m 0.8115  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-1.308   \u001b[0m | \u001b[0m 0.7825  \u001b[0m | \u001b[0m 0.2065  \u001b[0m | \u001b[0m 8.399   \u001b[0m | \u001b[0m 48.24   \u001b[0m | \u001b[0m 3.554   \u001b[0m | \u001b[0m 84.37   \u001b[0m | \u001b[0m 123.3   \u001b[0m | \u001b[0m 0.8172  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-1.368   \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 0.7727  \u001b[0m | \u001b[0m 2.786   \u001b[0m | \u001b[0m 81.13   \u001b[0m | \u001b[0m 13.56   \u001b[0m | \u001b[0m 389.3   \u001b[0m | \u001b[0m 52.51   \u001b[0m | \u001b[0m 0.9393  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-1.297   \u001b[0m | \u001b[0m 0.8344  \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 2.771   \u001b[0m | \u001b[0m 68.98   \u001b[0m | \u001b[0m 6.062   \u001b[0m | \u001b[0m 149.2   \u001b[0m | \u001b[0m 166.8   \u001b[0m | \u001b[0m 0.9169  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-1.664   \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.2739  \u001b[0m | \u001b[0m 9.142   \u001b[0m | \u001b[0m 49.57   \u001b[0m | \u001b[0m 6.098   \u001b[0m | \u001b[0m 477.3   \u001b[0m | \u001b[0m 102.7   \u001b[0m | \u001b[0m 0.8335  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-1.305   \u001b[0m | \u001b[0m 0.8571  \u001b[0m | \u001b[0m 0.5902  \u001b[0m | \u001b[0m 3.36    \u001b[0m | \u001b[0m 40.14   \u001b[0m | \u001b[0m 4.497   \u001b[0m | \u001b[0m 307.5   \u001b[0m | \u001b[0m 16.55   \u001b[0m | \u001b[0m 0.9198  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-2.136   \u001b[0m | \u001b[0m 0.8802  \u001b[0m | \u001b[0m 0.8506  \u001b[0m | \u001b[0m 7.845   \u001b[0m | \u001b[0m 47.73   \u001b[0m | \u001b[0m 12.06   \u001b[0m | \u001b[0m 487.0   \u001b[0m | \u001b[0m 64.07   \u001b[0m | \u001b[0m 0.8214  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-1.543   \u001b[0m | \u001b[0m 0.8425  \u001b[0m | \u001b[0m 0.9786  \u001b[0m | \u001b[0m 6.473   \u001b[0m | \u001b[0m 54.42   \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 181.0   \u001b[0m | \u001b[0m 13.54   \u001b[0m | \u001b[0m 0.8696  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-1.506   \u001b[0m | \u001b[0m 0.8449  \u001b[0m | \u001b[0m 0.6866  \u001b[0m | \u001b[0m 4.787   \u001b[0m | \u001b[0m 30.15   \u001b[0m | \u001b[0m 4.6     \u001b[0m | \u001b[0m 192.4   \u001b[0m | \u001b[0m 108.5   \u001b[0m | \u001b[0m 0.8154  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-1.39    \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.6127  \u001b[0m | \u001b[0m 5.602   \u001b[0m | \u001b[0m 29.68   \u001b[0m | \u001b[0m 14.43   \u001b[0m | \u001b[0m 70.67   \u001b[0m | \u001b[0m 74.41   \u001b[0m | \u001b[0m 0.9032  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-1.524   \u001b[0m | \u001b[0m 0.7672  \u001b[0m | \u001b[0m 0.7231  \u001b[0m | \u001b[0m 6.951   \u001b[0m | \u001b[0m 57.32   \u001b[0m | \u001b[0m 12.06   \u001b[0m | \u001b[0m 413.1   \u001b[0m | \u001b[0m 12.69   \u001b[0m | \u001b[0m 0.7878  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-1.275   \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.4312  \u001b[0m | \u001b[0m 4.009   \u001b[0m | \u001b[0m 60.52   \u001b[0m | \u001b[0m 9.797   \u001b[0m | \u001b[0m 191.5   \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 0.934   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-1.267   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 7.308   \u001b[0m | \u001b[0m 78.67   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 163.3   \u001b[0m | \u001b[0m 177.5   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-2.026   \u001b[0m | \u001b[0m 0.8561  \u001b[0m | \u001b[0m 0.8537  \u001b[0m | \u001b[0m 7.369   \u001b[0m | \u001b[0m 56.04   \u001b[0m | \u001b[0m 1.051   \u001b[0m | \u001b[0m 159.2   \u001b[0m | \u001b[0m 184.4   \u001b[0m | \u001b[0m 0.9148  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-1.263   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 7.529   \u001b[0m | \u001b[0m 76.45   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 163.4   \u001b[0m | \u001b[0m 156.0   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-1.238   \u001b[0m | \u001b[0m 0.8077  \u001b[0m | \u001b[0m 0.1632  \u001b[0m | \u001b[0m 3.38    \u001b[0m | \u001b[0m 85.51   \u001b[0m | \u001b[0m 6.438   \u001b[0m | \u001b[0m 81.55   \u001b[0m | \u001b[0m 90.24   \u001b[0m | \u001b[0m 0.8362  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-1.511   \u001b[0m | \u001b[0m 0.7901  \u001b[0m | \u001b[0m 0.7173  \u001b[0m | \u001b[0m 4.17    \u001b[0m | \u001b[0m 56.62   \u001b[0m | \u001b[0m 2.877   \u001b[0m | \u001b[0m 413.8   \u001b[0m | \u001b[0m 56.4    \u001b[0m | \u001b[0m 0.7803  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-1.673   \u001b[0m | \u001b[0m 0.9405  \u001b[0m | \u001b[0m 0.4343  \u001b[0m | \u001b[0m 9.979   \u001b[0m | \u001b[0m 89.41   \u001b[0m | \u001b[0m 10.39   \u001b[0m | \u001b[0m 154.0   \u001b[0m | \u001b[0m 170.7   \u001b[0m | \u001b[0m 0.9048  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-1.253   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 4.228   \u001b[0m | \u001b[0m 60.45   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 451.8   \u001b[0m | \u001b[0m 94.55   \u001b[0m | \u001b[0m 0.8292  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-1.471   \u001b[0m | \u001b[0m 0.8443  \u001b[0m | \u001b[0m 0.3312  \u001b[0m | \u001b[0m 6.781   \u001b[0m | \u001b[0m 23.24   \u001b[0m | \u001b[0m 9.176   \u001b[0m | \u001b[0m 204.9   \u001b[0m | \u001b[0m 101.2   \u001b[0m | \u001b[0m 0.8801  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-1.33    \u001b[0m | \u001b[0m 0.863   \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 63.55   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 147.8   \u001b[0m | \u001b[0m 142.7   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-1.317   \u001b[0m | \u001b[0m 0.8063  \u001b[0m | \u001b[0m 0.5614  \u001b[0m | \u001b[0m 4.754   \u001b[0m | \u001b[0m 54.03   \u001b[0m | \u001b[0m 8.903   \u001b[0m | \u001b[0m 181.8   \u001b[0m | \u001b[0m 12.25   \u001b[0m | \u001b[0m 0.8706  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-1.417   \u001b[0m | \u001b[0m 0.8686  \u001b[0m | \u001b[0m 0.3734  \u001b[0m | \u001b[0m 8.703   \u001b[0m | \u001b[0m 66.27   \u001b[0m | \u001b[0m 6.897   \u001b[0m | \u001b[0m 87.39   \u001b[0m | \u001b[0m 107.6   \u001b[0m | \u001b[0m 0.9492  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-1.259   \u001b[0m | \u001b[0m 0.8197  \u001b[0m | \u001b[0m 0.7058  \u001b[0m | \u001b[0m 2.247   \u001b[0m | \u001b[0m 37.23   \u001b[0m | \u001b[0m 3.657   \u001b[0m | \u001b[0m 197.3   \u001b[0m | \u001b[0m 15.12   \u001b[0m | \u001b[0m 0.7841  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-1.231   \u001b[0m | \u001b[0m 0.9124  \u001b[0m | \u001b[0m 0.08188 \u001b[0m | \u001b[0m 2.361   \u001b[0m | \u001b[0m 62.13   \u001b[0m | \u001b[0m 9.085   \u001b[0m | \u001b[0m 451.1   \u001b[0m | \u001b[0m 129.6   \u001b[0m | \u001b[0m 0.8665  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-1.229   \u001b[0m | \u001b[0m 0.9495  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 80.99   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 446.6   \u001b[0m | \u001b[0m 114.8   \u001b[0m | \u001b[0m 0.889   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-1.412   \u001b[0m | \u001b[0m 0.7548  \u001b[0m | \u001b[0m 0.3471  \u001b[0m | \u001b[0m 4.776   \u001b[0m | \u001b[0m 83.54   \u001b[0m | \u001b[0m 6.236   \u001b[0m | \u001b[0m 434.7   \u001b[0m | \u001b[0m 136.3   \u001b[0m | \u001b[0m 0.7505  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-1.24    \u001b[0m | \u001b[0m 0.8333  \u001b[0m | \u001b[0m 0.3204  \u001b[0m | \u001b[0m 2.42    \u001b[0m | \u001b[0m 60.38   \u001b[0m | \u001b[0m 1.404   \u001b[0m | \u001b[0m 472.3   \u001b[0m | \u001b[0m 148.6   \u001b[0m | \u001b[0m 0.8887  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-1.326   \u001b[0m | \u001b[0m 0.7961  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.179   \u001b[0m | \u001b[0m 78.91   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 469.0   \u001b[0m | \u001b[0m 134.0   \u001b[0m | \u001b[0m 0.787   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-1.283   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 37.54   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 485.4   \u001b[0m | \u001b[0m 143.3   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-1.282   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 63.78   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 491.1   \u001b[0m | \u001b[0m 131.3   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-1.324   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 32.25   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 173.9   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-1.232   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 77.79   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 465.0   \u001b[0m | \u001b[0m 113.7   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-1.234   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 86.13   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 488.0   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-1.241   \u001b[0m | \u001b[0m 0.8691  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.068   \u001b[0m | \u001b[0m 93.58   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 488.1   \u001b[0m | \u001b[0m 121.3   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-2.15    \u001b[0m | \u001b[0m 0.8233  \u001b[0m | \u001b[0m 0.8744  \u001b[0m | \u001b[0m 7.379   \u001b[0m | \u001b[0m 99.06   \u001b[0m | \u001b[0m 10.42   \u001b[0m | \u001b[0m 461.8   \u001b[0m | \u001b[0m 100.7   \u001b[0m | \u001b[0m 0.9307  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-1.285   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 89.83   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 462.9   \u001b[0m | \u001b[0m 155.2   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-1.278   \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 0.3673  \u001b[0m | \u001b[0m 5.207   \u001b[0m | \u001b[0m 60.72   \u001b[0m | \u001b[0m 4.553   \u001b[0m | \u001b[0m 93.57   \u001b[0m | \u001b[0m 152.1   \u001b[0m | \u001b[0m 0.8509  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-1.338   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 62.4    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 118.8   \u001b[0m | \u001b[0m 163.0   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-1.344   \u001b[0m | \u001b[0m 0.8794  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 43.96   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 98.4    \u001b[0m | \u001b[0m 172.3   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-1.249   \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 0.2258  \u001b[0m | \u001b[0m 5.433   \u001b[0m | \u001b[0m 44.86   \u001b[0m | \u001b[0m 8.813   \u001b[0m | \u001b[0m 113.0   \u001b[0m | \u001b[0m 137.4   \u001b[0m | \u001b[0m 0.8134  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-14.85   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 31.74   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 92.41   \u001b[0m | \u001b[0m 148.2   \u001b[0m | \u001b[0m 0.9382  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-1.339   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 64.84   \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 114.4   \u001b[0m | \u001b[0m 136.9   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-1.319   \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.255   \u001b[0m | \u001b[0m 46.38   \u001b[0m | \u001b[0m 12.73   \u001b[0m | \u001b[0m 130.5   \u001b[0m | \u001b[0m 128.3   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-1.344   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 76.73   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 98.23   \u001b[0m | \u001b[0m 158.1   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-1.341   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.144   \u001b[0m | \u001b[0m 51.8    \u001b[0m | \u001b[0m 12.1    \u001b[0m | \u001b[0m 108.3   \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-1.286   \u001b[0m | \u001b[0m 0.9252  \u001b[0m | \u001b[0m 0.8331  \u001b[0m | \u001b[0m 3.187   \u001b[0m | \u001b[0m 74.17   \u001b[0m | \u001b[0m 3.85    \u001b[0m | \u001b[0m 77.9    \u001b[0m | \u001b[0m 139.1   \u001b[0m | \u001b[0m 0.7794  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-1.34    \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 53.8    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 112.7   \u001b[0m | \u001b[0m 187.8   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-1.354   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.378   \u001b[0m | \u001b[0m 47.24   \u001b[0m | \u001b[0m 5.147   \u001b[0m | \u001b[0m 69.63   \u001b[0m | \u001b[0m 105.3   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-1.348   \u001b[0m | \u001b[0m 0.8678  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 48.61   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 86.68   \u001b[0m | \u001b[0m 194.6   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8432589523901574,\n",
       " 'learning_rate': 0.051055588083552005,\n",
       " 'max_depth': 4,\n",
       " 'min_child_samples': 51,\n",
       " 'min_child_weight': 12.505756351754851,\n",
       " 'n_estimators': 428,\n",
       " 'num_leaves': 11,\n",
       " 'subsample': 0.9335077173704511}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.23775659 -1.23450612 -1.23108711 -1.23705596]\n",
      "최대성능: -1.2310871116283506\n",
      "평균성능: -1.2351014472670574\n"
     ]
    }
   ],
   "source": [
    "pbounds = {'n_estimators' : (50, 500),\n",
    "           'learning_rate' : (0.01, 1.0),\n",
    "           'max_depth' : (2, 10),\n",
    "           'num_leaves' : (10, 200),\n",
    "           'min_child_samples' : (20, 100),\n",
    "           'min_child_weight' : (1, 15),\n",
    "           'subsample' : (0.75, 0.95),\n",
    "           'colsample_bytree' : (0.75, 0.95)}\n",
    "\n",
    "\n",
    "def lgbm_opt(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, colsample_bytree):\n",
    "    \n",
    "    params = {'n_estimators' : int(round(n_estimators)),\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "              'num_leaves' : int(round(num_leaves)),\n",
    "              'min_child_samples' : int(round(min_child_samples)),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'n_jobs' : -1}\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "    \n",
    "    score = cross_val_score(lgbm, X_train, y_train, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_opt, pbounds = pbounds, random_state = 516)\n",
    "\n",
    "BO_lgbm.maximize(init_points=40, n_iter=40)\n",
    "\n",
    "max_params = BO_lgbm.max['params']\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "display(max_params)\n",
    "\n",
    "# Step9. 최대화 하이퍼파라미터로 재학습\n",
    "lgbm_tun = LGBMClassifier(**max_params)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "scores = cross_val_score(lgbm_tun, X_val, y_val, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwd_w2v_pred = pd.DataFrame(lgbm_tun.predict_proba(test))\n",
    "clnt_te = pd.DataFrame({'CLNT_ID':[i for i in range(263104,375864)]})\n",
    "kwd_w2v_pred = pd.concat([clnt_te, kwd_w2v_pred],axis=1)\n",
    "kwd_w2v_pred.columns = ['CLNT_ID','F20','F30','F40','M20','M30','M40']\n",
    "kwd_w2v_pred.to_csv('kwd2_w2v_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# brand w2v bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('brand_w2v_train.csv', encoding = 'UTF-8')\n",
    "test = pd.read_csv('brand_w2v_test.csv', encoding = 'UTF-8')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size = 0.3, random_state = 516, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {'n_estimators' : (10, 350),\n",
    "           'learning_rate' : (0.03, 1.3),\n",
    "           'max_depth' : (3, 10),\n",
    "           'num_leaves' : (10, 200),\n",
    "           'min_child_samples' : (20, 100),\n",
    "           'min_child_weight' : (1, 10),\n",
    "           'subsample' : (0.75, 0.95),\n",
    "           'colsample_bytree' : (0.75, 0.95)}\n",
    "\n",
    "\n",
    "def lgbm_opt(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, colsample_bytree):\n",
    "    \n",
    "    \n",
    "    params = {'n_estimators' : int(round(n_estimators)),\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "              'num_leaves' : int(round(num_leaves)),\n",
    "              'min_child_samples' : int(round(min_child_samples)),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'n_jobs' : -1}\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "    \n",
    "    score = cross_val_score(lgbm, X_train, y_train, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_opt, pbounds = pbounds, random_state = 516)\n",
    "\n",
    "BO_lgbm.maximize(init_points=40, n_iter=40)\n",
    "\n",
    "max_params = BO_lgbm.max['params']\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "display(max_params)\n",
    "\n",
    "# Step9. 최대화 하이퍼파라미터로 재학습\n",
    "lgbm_tun = LGBMClassifier(**max_params)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "scores = cross_val_score(lgbm_tun, X_val, y_val, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_pred = pd.DataFrame(lgbm_clf.predict_proba(test))\n",
    "clnt_te = pd.DataFrame({'CLNT_ID':[i for i in range(263104,375864)]})\n",
    "w2v_pred = pd.concat([clnt_te, w2v_pred],axis=1)\n",
    "w2v_pred.columns = ['CLNT_ID','F20','F30','F40','M20','M30','M40']\n",
    "w2v_pred.to_csv('w2v_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clac1 w2v bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('clac1_w2v_train.csv', encoding = 'UTF-8')\n",
    "test = pd.read_csv('clac1_w2v_test.csv', encoding = 'UTF-8')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size = 0.3, random_state = 516, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {'n_estimators' : (10, 350),\n",
    "           'learning_rate' : (0.03, 1.3),\n",
    "           'max_depth' : (3, 10),\n",
    "           'num_leaves' : (10, 200),\n",
    "           'min_child_samples' : (20, 100),\n",
    "           'min_child_weight' : (1, 10),\n",
    "           'subsample' : (0.75, 0.95),\n",
    "           'colsample_bytree' : (0.75, 0.95)}\n",
    "\n",
    "\n",
    "def lgbm_opt(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, colsample_bytree):\n",
    "    \n",
    "    \n",
    "    params = {'n_estimators' : int(round(n_estimators)),\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "              'num_leaves' : int(round(num_leaves)),\n",
    "              'min_child_samples' : int(round(min_child_samples)),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'n_jobs' : -1}\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "    \n",
    "    score = cross_val_score(lgbm, X_train, y_train, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_opt, pbounds = pbounds, random_state = 516)\n",
    "\n",
    "BO_lgbm.maximize(init_points=40, n_iter=40)\n",
    "\n",
    "max_params = BO_lgbm.max['params']\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "display(max_params)\n",
    "\n",
    "# Step9. 최대화 하이퍼파라미터로 재학습\n",
    "lgbm_tun = LGBMClassifier(**max_params)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "scores = cross_val_score(lgbm_tun, X_val, y_val, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_pred = pd.DataFrame(lgbm_clf.predict_proba(test))\n",
    "clnt_te = pd.DataFrame({'CLNT_ID':[i for i in range(263104,375864)]})\n",
    "w2v_pred = pd.concat([clnt_te, w2v_pred],axis=1)\n",
    "w2v_pred.columns = ['CLNT_ID','F20','F30','F40','M20','M30','M40']\n",
    "w2v_pred.to_csv('w2v_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clac2 w2v bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('clac2_w2v_train.csv', encoding = 'UTF-8')\n",
    "test = pd.read_csv('clac2_w2v_test.csv', encoding = 'UTF-8')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size = 0.3, random_state = 516, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {'n_estimators' : (10, 350),\n",
    "           'learning_rate' : (0.03, 1.3),\n",
    "           'max_depth' : (3, 10),\n",
    "           'num_leaves' : (10, 200),\n",
    "           'min_child_samples' : (20, 100),\n",
    "           'min_child_weight' : (1, 10),\n",
    "           'subsample' : (0.75, 0.95),\n",
    "           'colsample_bytree' : (0.75, 0.95)}\n",
    "\n",
    "\n",
    "def lgbm_opt(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, colsample_bytree):\n",
    "    \n",
    "    \n",
    "    params = {'n_estimators' : int(round(n_estimators)),\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "              'num_leaves' : int(round(num_leaves)),\n",
    "              'min_child_samples' : int(round(min_child_samples)),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'n_jobs' : -1}\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "    \n",
    "    score = cross_val_score(lgbm, X_train, y_train, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_opt, pbounds = pbounds, random_state = 516)\n",
    "\n",
    "BO_lgbm.maximize(init_points=40, n_iter=40)\n",
    "\n",
    "max_params = BO_lgbm.max['params']\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "display(max_params)\n",
    "\n",
    "# Step9. 최대화 하이퍼파라미터로 재학습\n",
    "lgbm_tun = LGBMClassifier(**max_params)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "scores = cross_val_score(lgbm_tun, X_val, y_val, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_pred = pd.DataFrame(lgbm_clf.predict_proba(test))\n",
    "clnt_te = pd.DataFrame({'CLNT_ID':[i for i in range(263104,375864)]})\n",
    "w2v_pred = pd.concat([clnt_te, w2v_pred],axis=1)\n",
    "w2v_pred.columns = ['CLNT_ID','F20','F30','F40','M20','M30','M40']\n",
    "w2v_pred.to_csv('w2v_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clac3 w2v bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('clac3_w2v_train.csv', encoding = 'UTF-8')\n",
    "test = pd.read_csv('clac3_w2v_test.csv', encoding = 'UTF-8')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size = 0.3, random_state = 516, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.388   \u001b[0m | \u001b[0m 0.9123  \u001b[0m | \u001b[0m 0.7113  \u001b[0m | \u001b[0m 4.115   \u001b[0m | \u001b[0m 61.01   \u001b[0m | \u001b[0m 16.06   \u001b[0m | \u001b[0m 351.3   \u001b[0m | \u001b[0m 113.0   \u001b[0m | \u001b[0m 0.789   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-16.8    \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 0.8463  \u001b[0m | \u001b[0m 6.922   \u001b[0m | \u001b[0m 78.23   \u001b[0m | \u001b[0m 4.343   \u001b[0m | \u001b[0m 278.3   \u001b[0m | \u001b[0m 62.69   \u001b[0m | \u001b[0m 0.8719  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.834   \u001b[0m | \u001b[0m 0.8565  \u001b[0m | \u001b[0m 0.7491  \u001b[0m | \u001b[0m 8.395   \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 11.26   \u001b[0m | \u001b[0m 303.7   \u001b[0m | \u001b[0m 67.81   \u001b[0m | \u001b[0m 0.8451  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.663   \u001b[0m | \u001b[0m 0.8397  \u001b[0m | \u001b[0m 0.4175  \u001b[0m | \u001b[0m 12.86   \u001b[0m | \u001b[0m 20.38   \u001b[0m | \u001b[0m 18.8    \u001b[0m | \u001b[0m 266.5   \u001b[0m | \u001b[0m 136.0   \u001b[0m | \u001b[0m 0.7549  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.458   \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 80.52   \u001b[0m | \u001b[0m 7.472   \u001b[0m | \u001b[0m 244.8   \u001b[0m | \u001b[0m 148.3   \u001b[0m | \u001b[0m 0.8592  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-1.29    \u001b[0m | \u001b[95m 0.9255  \u001b[0m | \u001b[95m 0.08759 \u001b[0m | \u001b[95m 7.121   \u001b[0m | \u001b[95m 52.02   \u001b[0m | \u001b[95m 1.212   \u001b[0m | \u001b[95m 172.0   \u001b[0m | \u001b[95m 161.4   \u001b[0m | \u001b[95m 0.8305  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.47    \u001b[0m | \u001b[0m 0.7666  \u001b[0m | \u001b[0m 0.2404  \u001b[0m | \u001b[0m 9.781   \u001b[0m | \u001b[0m 36.57   \u001b[0m | \u001b[0m 14.19   \u001b[0m | \u001b[0m 366.8   \u001b[0m | \u001b[0m 84.47   \u001b[0m | \u001b[0m 0.8177  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.447   \u001b[0m | \u001b[0m 0.9158  \u001b[0m | \u001b[0m 0.4006  \u001b[0m | \u001b[0m 11.08   \u001b[0m | \u001b[0m 95.08   \u001b[0m | \u001b[0m 8.863   \u001b[0m | \u001b[0m 141.8   \u001b[0m | \u001b[0m 80.58   \u001b[0m | \u001b[0m 0.9248  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-1.258   \u001b[0m | \u001b[95m 0.8433  \u001b[0m | \u001b[95m 0.05106 \u001b[0m | \u001b[95m 5.093   \u001b[0m | \u001b[95m 44.67   \u001b[0m | \u001b[95m 16.61   \u001b[0m | \u001b[95m 352.2   \u001b[0m | \u001b[95m 10.87   \u001b[0m | \u001b[95m 0.9335  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.358   \u001b[0m | \u001b[0m 0.9359  \u001b[0m | \u001b[0m 0.356   \u001b[0m | \u001b[0m 6.133   \u001b[0m | \u001b[0m 98.22   \u001b[0m | \u001b[0m 8.654   \u001b[0m | \u001b[0m 171.5   \u001b[0m | \u001b[0m 188.4   \u001b[0m | \u001b[0m 0.8047  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-1.478   \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.4286  \u001b[0m | \u001b[0m 5.733   \u001b[0m | \u001b[0m 54.39   \u001b[0m | \u001b[0m 17.14   \u001b[0m | \u001b[0m 396.1   \u001b[0m | \u001b[0m 156.7   \u001b[0m | \u001b[0m 0.9073  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-1.324   \u001b[0m | \u001b[0m 0.8046  \u001b[0m | \u001b[0m 0.6025  \u001b[0m | \u001b[0m 3.954   \u001b[0m | \u001b[0m 23.13   \u001b[0m | \u001b[0m 2.371   \u001b[0m | \u001b[0m 170.7   \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 0.8522  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-1.869   \u001b[0m | \u001b[0m 0.8573  \u001b[0m | \u001b[0m 0.8136  \u001b[0m | \u001b[0m 6.774   \u001b[0m | \u001b[0m 49.25   \u001b[0m | \u001b[0m 14.78   \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 0.7571  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-11.63   \u001b[0m | \u001b[0m 0.8111  \u001b[0m | \u001b[0m 0.9066  \u001b[0m | \u001b[0m 8.943   \u001b[0m | \u001b[0m 89.94   \u001b[0m | \u001b[0m 5.784   \u001b[0m | \u001b[0m 264.1   \u001b[0m | \u001b[0m 54.35   \u001b[0m | \u001b[0m 0.7574  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-1.346   \u001b[0m | \u001b[0m 0.9476  \u001b[0m | \u001b[0m 0.2786  \u001b[0m | \u001b[0m 4.541   \u001b[0m | \u001b[0m 29.68   \u001b[0m | \u001b[0m 5.603   \u001b[0m | \u001b[0m 372.9   \u001b[0m | \u001b[0m 138.2   \u001b[0m | \u001b[0m 0.7593  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.716   \u001b[0m | \u001b[0m 0.7706  \u001b[0m | \u001b[0m 0.5645  \u001b[0m | \u001b[0m 9.64    \u001b[0m | \u001b[0m 94.17   \u001b[0m | \u001b[0m 14.61   \u001b[0m | \u001b[0m 255.7   \u001b[0m | \u001b[0m 99.83   \u001b[0m | \u001b[0m 0.8319  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-1.796   \u001b[0m | \u001b[0m 0.9155  \u001b[0m | \u001b[0m 0.3947  \u001b[0m | \u001b[0m 12.08   \u001b[0m | \u001b[0m 49.37   \u001b[0m | \u001b[0m 14.96   \u001b[0m | \u001b[0m 368.4   \u001b[0m | \u001b[0m 187.7   \u001b[0m | \u001b[0m 0.8324  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-1.97    \u001b[0m | \u001b[0m 0.7567  \u001b[0m | \u001b[0m 0.8552  \u001b[0m | \u001b[0m 9.31    \u001b[0m | \u001b[0m 53.8    \u001b[0m | \u001b[0m 12.27   \u001b[0m | \u001b[0m 199.8   \u001b[0m | \u001b[0m 167.3   \u001b[0m | \u001b[0m 0.7656  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.134   \u001b[0m | \u001b[0m 0.8884  \u001b[0m | \u001b[0m 0.9181  \u001b[0m | \u001b[0m 9.336   \u001b[0m | \u001b[0m 45.03   \u001b[0m | \u001b[0m 17.1    \u001b[0m | \u001b[0m 331.2   \u001b[0m | \u001b[0m 188.5   \u001b[0m | \u001b[0m 0.7885  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-1.799   \u001b[0m | \u001b[0m 0.8507  \u001b[0m | \u001b[0m 0.5242  \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 74.47   \u001b[0m | \u001b[0m 9.265   \u001b[0m | \u001b[0m 340.8   \u001b[0m | \u001b[0m 90.24   \u001b[0m | \u001b[0m 0.7657  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-1.344   \u001b[0m | \u001b[0m 0.9121  \u001b[0m | \u001b[0m 0.7054  \u001b[0m | \u001b[0m 10.47   \u001b[0m | \u001b[0m 38.23   \u001b[0m | \u001b[0m 16.48   \u001b[0m | \u001b[0m 125.4   \u001b[0m | \u001b[0m 14.15   \u001b[0m | \u001b[0m 0.8084  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-1.53    \u001b[0m | \u001b[0m 0.8549  \u001b[0m | \u001b[0m 0.7477  \u001b[0m | \u001b[0m 8.343   \u001b[0m | \u001b[0m 77.01   \u001b[0m | \u001b[0m 19.45   \u001b[0m | \u001b[0m 285.1   \u001b[0m | \u001b[0m 25.25   \u001b[0m | \u001b[0m 0.7882  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-1.518   \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 0.4625  \u001b[0m | \u001b[0m 8.894   \u001b[0m | \u001b[0m 33.77   \u001b[0m | \u001b[0m 14.73   \u001b[0m | \u001b[0m 188.8   \u001b[0m | \u001b[0m 83.4    \u001b[0m | \u001b[0m 0.7747  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-1.315   \u001b[0m | \u001b[0m 0.907   \u001b[0m | \u001b[0m 0.6675  \u001b[0m | \u001b[0m 4.311   \u001b[0m | \u001b[0m 65.69   \u001b[0m | \u001b[0m 7.099   \u001b[0m | \u001b[0m 129.6   \u001b[0m | \u001b[0m 181.0   \u001b[0m | \u001b[0m 0.8782  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-1.553   \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.3838  \u001b[0m | \u001b[0m 6.568   \u001b[0m | \u001b[0m 37.73   \u001b[0m | \u001b[0m 4.244   \u001b[0m | \u001b[0m 272.7   \u001b[0m | \u001b[0m 140.3   \u001b[0m | \u001b[0m 0.8603  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-1.305   \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 0.196   \u001b[0m | \u001b[0m 7.036   \u001b[0m | \u001b[0m 59.91   \u001b[0m | \u001b[0m 6.3     \u001b[0m | \u001b[0m 334.8   \u001b[0m | \u001b[0m 24.16   \u001b[0m | \u001b[0m 0.9098  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-1.262   \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.01085 \u001b[0m | \u001b[0m 12.17   \u001b[0m | \u001b[0m 95.6    \u001b[0m | \u001b[0m 5.464   \u001b[0m | \u001b[0m 295.9   \u001b[0m | \u001b[0m 124.8   \u001b[0m | \u001b[0m 0.8799  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-1.513   \u001b[0m | \u001b[0m 0.807   \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 9.58    \u001b[0m | \u001b[0m 68.2    \u001b[0m | \u001b[0m 4.477   \u001b[0m | \u001b[0m 206.3   \u001b[0m | \u001b[0m 87.81   \u001b[0m | \u001b[0m 0.821   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-1.341   \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.2961  \u001b[0m | \u001b[0m 5.277   \u001b[0m | \u001b[0m 13.58   \u001b[0m | \u001b[0m 3.513   \u001b[0m | \u001b[0m 308.8   \u001b[0m | \u001b[0m 177.8   \u001b[0m | \u001b[0m 0.8807  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-1.408   \u001b[0m | \u001b[0m 0.7812  \u001b[0m | \u001b[0m 0.1342  \u001b[0m | \u001b[0m 10.75   \u001b[0m | \u001b[0m 12.23   \u001b[0m | \u001b[0m 3.407   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 124.8   \u001b[0m | \u001b[0m 0.7769  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-22.91   \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.9028  \u001b[0m | \u001b[0m 11.77   \u001b[0m | \u001b[0m 17.79   \u001b[0m | \u001b[0m 1.742   \u001b[0m | \u001b[0m 358.9   \u001b[0m | \u001b[0m 71.69   \u001b[0m | \u001b[0m 0.8115  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-1.36    \u001b[0m | \u001b[0m 0.7825  \u001b[0m | \u001b[0m 0.2065  \u001b[0m | \u001b[0m 11.0    \u001b[0m | \u001b[0m 41.77   \u001b[0m | \u001b[0m 4.466   \u001b[0m | \u001b[0m 122.9   \u001b[0m | \u001b[0m 123.3   \u001b[0m | \u001b[0m 0.8172  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-1.392   \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 0.7727  \u001b[0m | \u001b[0m 3.982   \u001b[0m | \u001b[0m 78.77   \u001b[0m | \u001b[0m 18.05   \u001b[0m | \u001b[0m 326.2   \u001b[0m | \u001b[0m 52.51   \u001b[0m | \u001b[0m 0.9393  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-1.34    \u001b[0m | \u001b[0m 0.8344  \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 3.964   \u001b[0m | \u001b[0m 65.1    \u001b[0m | \u001b[0m 7.87    \u001b[0m | \u001b[0m 166.1   \u001b[0m | \u001b[0m 166.8   \u001b[0m | \u001b[0m 0.9169  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-1.592   \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.2739  \u001b[0m | \u001b[0m 11.93   \u001b[0m | \u001b[0m 43.27   \u001b[0m | \u001b[0m 7.918   \u001b[0m | \u001b[0m 384.9   \u001b[0m | \u001b[0m 102.7   \u001b[0m | \u001b[0m 0.8335  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-1.38    \u001b[0m | \u001b[0m 0.8571  \u001b[0m | \u001b[0m 0.5902  \u001b[0m | \u001b[0m 4.7     \u001b[0m | \u001b[0m 32.65   \u001b[0m | \u001b[0m 5.746   \u001b[0m | \u001b[0m 271.7   \u001b[0m | \u001b[0m 16.55   \u001b[0m | \u001b[0m 0.9198  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-2.005   \u001b[0m | \u001b[0m 0.8802  \u001b[0m | \u001b[0m 0.8506  \u001b[0m | \u001b[0m 10.31   \u001b[0m | \u001b[0m 41.2    \u001b[0m | \u001b[0m 16.01   \u001b[0m | \u001b[0m 391.3   \u001b[0m | \u001b[0m 64.07   \u001b[0m | \u001b[0m 0.8214  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-22.09   \u001b[0m | \u001b[0m 0.8425  \u001b[0m | \u001b[0m 0.9786  \u001b[0m | \u001b[0m 8.591   \u001b[0m | \u001b[0m 48.73   \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 187.3   \u001b[0m | \u001b[0m 13.54   \u001b[0m | \u001b[0m 0.8696  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-1.554   \u001b[0m | \u001b[0m 0.8449  \u001b[0m | \u001b[0m 0.6866  \u001b[0m | \u001b[0m 6.484   \u001b[0m | \u001b[0m 21.42   \u001b[0m | \u001b[0m 5.886   \u001b[0m | \u001b[0m 194.9   \u001b[0m | \u001b[0m 108.5   \u001b[0m | \u001b[0m 0.8154  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-1.48    \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.6127  \u001b[0m | \u001b[0m 7.503   \u001b[0m | \u001b[0m 20.89   \u001b[0m | \u001b[0m 19.23   \u001b[0m | \u001b[0m 113.8   \u001b[0m | \u001b[0m 74.41   \u001b[0m | \u001b[0m 0.9032  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-1.272   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.235   \u001b[0m | \u001b[0m 60.71   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 371.8   \u001b[0m | \u001b[0m 84.63   \u001b[0m | \u001b[0m 0.8548  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-1.381   \u001b[0m | \u001b[0m 0.8655  \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 8.639   \u001b[0m | \u001b[0m 43.16   \u001b[0m | \u001b[0m 5.19    \u001b[0m | \u001b[0m 122.9   \u001b[0m | \u001b[0m 125.6   \u001b[0m | \u001b[0m 0.7527  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-1.536   \u001b[0m | \u001b[0m 0.8239  \u001b[0m | \u001b[0m 0.4002  \u001b[0m | \u001b[0m 10.01   \u001b[0m | \u001b[0m 60.86   \u001b[0m | \u001b[0m 9.001   \u001b[0m | \u001b[0m 169.2   \u001b[0m | \u001b[0m 116.0   \u001b[0m | \u001b[0m 0.8351  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-16.75   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 50.86   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 304.3   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-1.261   \u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 6.052   \u001b[0m | \u001b[0m 72.58   \u001b[0m | \u001b[0m 16.3    \u001b[0m | \u001b[0m 358.1   \u001b[0m | \u001b[0m 36.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-1.392   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.497   \u001b[0m | \u001b[0m 6.126   \u001b[0m | \u001b[0m 48.22   \u001b[0m | \u001b[0m 12.79   \u001b[0m | \u001b[0m 142.8   \u001b[0m | \u001b[0m 91.79   \u001b[0m | \u001b[0m 0.7872  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-1.261   \u001b[0m | \u001b[0m 0.8172  \u001b[0m | \u001b[0m 0.1225  \u001b[0m | \u001b[0m 4.064   \u001b[0m | \u001b[0m 28.82   \u001b[0m | \u001b[0m 9.897   \u001b[0m | \u001b[0m 160.5   \u001b[0m | \u001b[0m 135.8   \u001b[0m | \u001b[0m 0.7847  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-7.341   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 58.94   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 144.9   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-1.287   \u001b[0m | \u001b[0m 0.8943  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 48.7    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 195.3   \u001b[0m | \u001b[0m 130.3   \u001b[0m | \u001b[0m 0.75    \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "pbounds = {'n_estimators' : (100, 400),\n",
    "           'learning_rate' : (0.01, 1.0),\n",
    "           'max_depth' : (3, 13),\n",
    "           'num_leaves' : (10, 200),\n",
    "           'min_child_samples' : (10, 100),\n",
    "           'min_child_weight' : (1, 20),\n",
    "           'subsample' : (0.75, 0.95),\n",
    "           'colsample_bytree' : (0.75, 0.95)}\n",
    "\n",
    "\n",
    "def lgbm_opt(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, colsample_bytree):\n",
    "    \n",
    "    \n",
    "    params = {'n_estimators' : int(round(n_estimators)),\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "              'num_leaves' : int(round(num_leaves)),\n",
    "              'min_child_samples' : int(round(min_child_samples)),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'n_jobs' : -1}\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "    \n",
    "    score = cross_val_score(lgbm, X_train, y_train, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_opt, pbounds = pbounds, random_state = 516)\n",
    "\n",
    "BO_lgbm.maximize(init_points=40, n_iter=40)\n",
    "\n",
    "max_params = BO_lgbm.max['params']\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "display(max_params)\n",
    "\n",
    "# Step9. 최대화 하이퍼파라미터로 재학습\n",
    "lgbm_tun = LGBMClassifier(**max_params)\n",
    "lgbm_tun.fit(X_train, y_train)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 516)\n",
    "scores = cross_val_score(lgbm_tun, X_val, y_val, cv = skfold, scoring = 'neg_log_loss', n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8432589523901574,\n",
       " 'learning_rate': 0.051055588083552005,\n",
       " 'max_depth': 5,\n",
       " 'min_child_samples': 45,\n",
       " 'min_child_weight': 16.614955048810156,\n",
       " 'n_estimators': 352,\n",
       " 'num_leaves': 11,\n",
       " 'subsample': 0.9335077173704511}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.27318992 -1.27103356 -1.27066252 -1.27162127]\n",
      "최대성능: -1.2706625238476337\n",
      "평균성능: -1.2716268163090936\n"
     ]
    }
   ],
   "source": [
    "display(max_params)\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_w2v_pred = pd.DataFrame(lgbm_tun.predict_proba(test))\n",
    "clnt_te = pd.DataFrame({'CLNT_ID':[i for i in range(263104,375864)]})\n",
    "clac3_w2v_pred = pd.concat([clnt_te, clac3_w2v_pred],axis=1)\n",
    "clac3_w2v_pred.columns = ['CLNT_ID','F20','F30','F40','M20','M30','M40']\n",
    "clac3_w2v_pred.to_csv('clac3_w2v_pred.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
